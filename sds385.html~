<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="generator" content="CoffeeCup HTML Editor (www.coffeecup.com)">
    <meta name="dcterms.created" content="Wed, 21 Jan 2015 05:15:16 GMT">
    <meta name="description" content="">
    <meta name="keywords" content="">
    <title></title>
    
    <!--[if IE]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <title>Other</title>


  <link rel="stylesheet" type="text/css" href="style.css" media="screen" />

</head>



<body>

<div id="header">
<h1>Purnamrita Sarkar</h1>

<div id="menu">
<ul id="nav">

  <li><a href="index.html">Home</a></li>

  <li></li>

  <li><a href="Research1.html">Research</a></li>

  <li><a href="teaching.html">Teaching<span style="font-weight: bold;"></span></a></li>

</ul>

</div>

</div>


<div id="content">
<div style="color: rgb(0, 0, 0);" id="right">
<h2><a name="3"></a>SDS 385: Statistics Models for Big Data</h2>
    <br />

<span style="font-weight: bold;">08/25 </span>: Syllabus, and introduction <a href="SDS385/lecture1-ps.pdf"> [Slides]. </a> Exam <a href="SDS385/exam.pdf"> [Here]. </a> </a> Exam solutions <a href="SDS385/exam_sol.pdf"> [Here]. </a> <br /><br/>
<span style="font-weight: bold;">08/31 </span>: Linear regression <a href="SDS385/lecture2-ps.pdf"> [Slides]. </a> <br /><br/>
    <span style="font-weight: bold;">09/2 </span>: Gradient Descent and Newton Raphson <a href="SDS385/lecture2-ps.pdf"> [Slides]. </a> <br /><br/>
   <span style="font-weight: bold;">09/9 </span>: Stochastic Gradient Descent <a href="SDS385/lecture3-ps.pdf"> [Slides]. </a> <br /><br/>
    <span style="font-weight: bold;">09/13 </span>: HW1 is out <a href="SDS385/HW1.pdf"> [here]. </a> Latex file is <a href="SDS385/HW1.tex"> [here].  </a> Dataset here <a href="SDS385/logistic_regression.zip"> [here]. </a> Solutions are  <a href="SDS385/HW1-sol.pdf"> [here]. </a> and <a href="SDS385/sds385_hw1_lr_yx.html"> [here]. </a> <br /><br/>
<span style="font-weight: bold;">Reading </span>: Derivatives w.r.t vectors <a href="https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf"> [Here]. </a> <br/><br/>
   <span style="font-weight: bold;">Reading </span>: Chapters 9.1 9.2 and 9.3 in <a href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf"> [Convex Optimization book] </a> by Boyd and Vandenberghe. <br /><br/>
    <span style="font-weight: bold;">09/17 </span>: Momentum methods and subgradients <a href="SDS385/lecture4-ps.pdf"> [Slides]. </a>  <br /><br/>
   <span style="font-weight: bold;">Reading </span>: Nesterov's accelerated gradient vs Polyak's momentum <a href="http://proceedings.mlr.press/v28/sutskever13.pdf">here </a>.<br /><br/>
  <!---<span style="font-weight: bold;">09/23 </span>: HW1 is out <a href="SDS385/HW1.pdf"> [here]. </a> Latex file is <a href="SDS385/HW1.tex"> [here]. </a> Please download the dataset from the Canvas page. Solutions are  <a href="SDS385/SDS_385_HW1.pdf"> [here]. </a> and <a href="SDS385/sds385_hw1_lr_yx.html"> [here] (Thanks to Gail!!). </a> <br /><br/>--->
  <!---  <span style="font-weight: bold;">09/24 </span>: Momentum methods and Subgradients <a href="SDS385/lecture4-ps.pdf"> [Slides]. </a> <br/><br/>--->
    <span style="font-weight: bold;">Reading </span>: Stephen Boyd's notes. <a href="https://web.stanford.edu/class/ee364b/lectures/subgrad_method_notes.pdf">here </a>.<br /><br/>
     <span style="font-weight: bold;">09/24 </span>: Proximal methods <a href="SDS385/lecture5-ps.pdf"> [Slides]. </a> <br/><br/>
<span style="font-weight: bold;">09/24 </span>: Duality <a href="SDS385/duality.pdf"> [Slides]. </a> <br/><br/>
     <span style="font-weight: bold;">Reading </span>: A note on optimization and duality <a href="https://www-cs.stanford.edu/people/davidknowles/lagrangian_duality.pdf"> [Here]. </a> <br/><br/>
     
<span style="font-weight: bold;">Reading </span>: Proximal methods <a href="https://web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf"> [Here]. </a> <br/><br/>

    <span style="font-weight: bold;">10/8 </span>: Reading: Support vector machines <a href="http://www.robots.ox.ac.uk/~az/lectures/ml/lect2.pdf"> [here]. </a>  <br /><br/>
     <span style="font-weight: bold;">10/8,10 </span>: Large scale SVM optimization<a href="SDS385/lecture6-ps.pdf"> [Slides]. </a> <br/><br/>
     <!---<span style="font-weight: bold;">10/10 </span>: Project details are <a href="SDS385/projects_updated1.htm"> [out]. </a> <br/><br/>--->
   
    <span style="font-weight: bold;">10/15 </span>: Approximate nearest neighbors-minhashing<a href="SDS385/lecture7-ps.pdf"> [Slides]. </a> <br/><br/>

    <span style="font-weight: bold;">10/22 </span>: Approximate nearest neighbors-LSH<a href="SDS385/lecture8-ps.pdf"> [Slides]. </a> <br/><br/>
    <span style="font-weight: bold;">Reading </span>: The Mining of Massive Datasets book-Chapter 3. <a href="http://www.mmds.org/#book">here </a>.<br /><br/>


    <span style="font-weight: bold;">10/27 </span>: HW2 is out <a href="SDS385/HW2.pdf"> [here]. </a> Latex file is <a href="SDS385/HW2.tex"> [here]. </a> Solution pdf is <a href="SDS385/HW2-sol.pdf"> [here]</a> <!---, hashing bit is <a href="SDS385/p4_hash.html"> here </a>, and denoising with lasso penalty is <a href="p1_fused_lasso.html"> here </a>  <br /><br/>
    <!---<span style="font-weight: bold;">10/25 </span>: Practice problems<a href="SDS385/practice_problems.pdf"> [Here]. </a> <br/><br/>
    -->
<br/><br/>
<span style="font-weight: bold;">10/27 </span>: KD trees<a href="SDS385/kdtrees.pdf"> [Here]. </a> <br/><br/>

<span style="font-weight: bold;">11/06 </span>: PCA and LDA  <a href="SDS385/dimreduction.pdf"> [Here]. </a> <br/><br/>

    <span style="font-weight: bold;">11/17 </span>: HW3 is out <a href="SDS385/HW3new.pdf"> [here]. </a> Latex file is <a href="SDS385/HW3new.tex"> [here]. </a> Dataset is on canvas. 
<br/><br/>
Solutions are <a href="SDS385/HW3-sol.pdf"> [here] </a>  <br /><br/>


<span style="font-weight: bold;">10/27 </span>: Map reduce <a href="https://cseweb.ucsd.edu/classes/sp16/cse291-e/applications/ln/lecture14.html"> [Here]. </a> <br/><br/>
<!---
<span style="font-weight: bold;">10/27 </span>: K-means with Map reduce <a href="https://stanford.edu/~rezab/classes/cme323/S16/projects_reports/bodoia.pdf"> [Here]. </a> <br/><br/>
-->

<span style="font-weight: bold;">11/04 </span>: More Map-reduce <a href="SDS385/mapreduce.pdf"> [Here]. </a> <br/><br/>

<!---
    <span style="font-weight: bold;">11/04 </span>: Distributed computing - PODC tutorial<a href="https://www.podc.org/data/podc2018/podc2018-tutorial-alistarh.pdf"> [Here]. </a>
<br/><br/>
<span style="font-weight: bold;">11/06 </span>: PCA and LDA (a detour for better understanding the distrance metric learning paper) <a href="SDS385/dimreduction.pdf"> [Here]. </a> <br/><br/>
---->
<!--    <br/><br/>
    <span style="font-weight: bold;">11/5 </span>: Emily Fox's notes <a href="https://courses.cs.washington.edu/courses/cse547/15sp/slides/fusedlasso-lassoSolvers-annotated.pdf"> [Here]. </a>
    <br/><br/>
    <span style="font-weight: bold;">11/7 </span>: Networks <a href="SDS385/community.pdf"> [Here]. </a>
    <br/><br/>
    <span style="font-weight: bold;">11/14,19 </span>: Cho-Jui Hsieh's fantastic lecture notes from UC Davis <a href="SDS385/hsieh_7.pdf"> [Here]. </a> Distributed SGD for matrix completion <a href="SDS385/sgd_matcompl_kdd.pdf">[Here]. </a>--->

    

<!---    <span style="font-weight: bold;">11/26 </span>: Sampling for matrix multiplication<a href="SDS385/lecture9-ps.pdf"> [Slides]. </a> <br/><br/>`-->
  <!----  <span style="font-weight: bold;">11/18 </span>: Ranking and pagerank, semi-supervised learning<a href="SDS385/lecture10-ps.pdf"> [Slides]. </a> <br/><br/>
<span style="font-weight: bold;">11/26 </span>: Sampling for matrix multiplication<a href="SDS385/lecture9-ps.pdf"> [Slides]. </a> <br/><br/>
    <span style="font-weight: bold;">12/2 </span>: Bootstrap and subsampling <a href="SDS385/lecture11-ps.pdf"> [Slides]. </a> <br/><br/>
<span style="font-weight: bold;">12/2 </span>: Sampling for matrix multiplication <a href="SDS385/lecture9-ps.pdf"> [Slides]. </a> <br/><br/>
<span style="font-weight: bold;">12/10 </span>: Final exam is here <a href="SDS385/sds385_final-v2.pdf"> [Here]. </a> and tex file <a href="SDS385/final.tex"> [Here]. </a><br/><br/>
---->
</div>

</body>
</html>

  </body>
</html>
