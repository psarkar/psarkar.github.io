\documentclass[11pt]{article}
\usepackage[left=1.25in,top=1in,right=1.25in,bottom=1.00in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{amsbsy}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{verbatim}
\usepackage{epsfig}
\usepackage{color}
\usepackage[round]{natbib}
\usepackage{multirow} 
\newcommand{\logit}{\mbox{logit}}
\newcommand{\probit}{\mbox{probit}}
\newcommand{\hiw}{{\small\textsc{HIW}}}
\newcommand{\iw}{{\small\textsc{IW}}}
\newcommand{\N}{\mbox{N}}
\newcommand{\Be}{\mbox{Be}}
\newcommand{\dd}{\mbox{d}}
\newcommand{\C}{\; | \;}
\newcommand{\var}{\text{var}}
\newcommand{\F}{\mathcal{F}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Example]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\R}{\mathcal{R}}
\renewcommand{\S}{\mathcal{S}}

\begin{document}

\title{{\bf Homework Assignment 5}\\Due  May 3rd by  midnight} %\footnote{I am happy to extend it to 11th})}
\author{SDS 384-11 Theoretical Statistics}

\date{}

\maketitle{}
%\textbf{Set algebra and probability laws.}
\begin{enumerate}%\item Read Bertsekas and Tsitsiklis, sections 1.1, 1.2 and 1.3.
%\section{Jeffrey's prior}
%\begin{enumerate}
%\end{enumerate}


\item In class, you upper bounded the Rademacher complexity of a function class. Now you will derive a lower bound.
\begin{enumerate}
	\item For function classes $\F$ with function values in $[0,1]$, prove that $E\|\hat{P}_n-P\|_\F\geq \frac{\R_\F}{2}-\sqrt{\frac{\log 2}{2n}}$.
	\textit{Hint: may be it is easier to start from $\R_\F$ and show that $\R_F\leq 2E\|\hat{P}_n-P\|_\F+\sqrt{\frac{2\log 2}{n}}$. In order to do this, you would need to add and subtract $E[f(X)]$ and then use triangle inequality.}
	\item Now prove that $\|P-\hat{P}_n\|_\F\geq E\|P-\hat{P}_n\|_\F-\epsilon$ with probability at least $1-\exp(-cn\epsilon^2)$ for some constant $c$.
	\item Recall the class of all subsets with finite size in $[0,1]$? Prove that then Rademacher complexity of this class is at least $1/2$. What does this imply?
\end{enumerate}

%\begin{comment}
\item In this exercise, we explore the connection between VC dimension and
metric entropy. Given a set class $\S$ with finite VC dimension $\nu$, we show that the
function class $\F_S := {1_S, S \in \S}$ of indicator functions has metric entropy at most
\begin{align}
N(\delta;\F_\S,L^1(P))\leq \left(\frac{K\log(3e/\delta)}{\delta}\right)^{\nu}\ \ \ \ \mbox{For a constant $K$}
\end{align}
Let $\{1_{S^1},\dots,1_{S^N}\}$ be a maximal delta packing in the $L^1(P)$ norm, so that:
\begin{align*}
\|1_{S_i}-1_{S_j}\|_1=E[|1_{S_i}(X)-1_{S_j}(X)|]>\delta \qquad \mbox{for all $i\neq j$}
\end{align*}
This is an upper bound on the $\delta$ covering number.
\begin{enumerate}
	\item Suppose that we generate n samples $X_i, i = 1, \dots , n$ drawn i.i.d. from $P$. Show 
that the probability that every set $S_i$ picks out a different subset of $\{X_1,\dots, X_n\}$ is at least $1-{N\choose 2}(1-\delta)^n$.
\item Using part (a), show that for $N \geq 2$ and $n = \lceil 2 \log N/\delta\rceil$, there exists a set of $n$ points
from which $\S$ picks out at least N subsets, and conclude that $N \leq \left(\frac{3e \log N}{\nu\delta}\right)^\nu$.
\item Use part (b) to show that Eq (1) holds with $K:=3e^2/(e-1)$.
\textit{Hint: Note that you have $\frac{N^{1/\nu}}{\log N}\leq \frac{3e}{\nu\delta}$. Let $g(x)=x/\log x$. We are solving for $g(m^{1/\nu})\leq 3e/\delta$. Prove that $g(x)\leq y$ implies $x\leq \frac{e}{e-1}y\log y$.}
\end{enumerate}
\item We will find the covering number of ellipses in this problem.  Given a collection of positive numbers $\{\mu_j,j=1\dots d\}$, consider the ellipse $$\mathcal{E}=\{\theta\in\R^d : \sum_i \theta_i^2/\mu_i^2\leq 1\}$$
\begin{enumerate}
	\item Show that $$\log N(\epsilon; \mathcal{E},\|.\|_2)\geq d\log (1/\epsilon)+\sum_{j=1}^d\log \mu_j$$
	\item Now consider an infinite-dimensional ellipse, specified by the sequence $\mu_j = j-2\beta$
for some parameter $\beta > 1/2$. Show that
$$\log N(\epsilon; \mathcal{E},\|.\|_2)\geq C \left(\frac{1}{\epsilon}\right)^{1/2\beta},$$
where $\|\theta-\theta'\|_{\ell_2}^2=\sum_{j=1}^\infty (\theta_i-\theta_j)^2$ is the squared $\ell_2$-norm on the space of square summable sequences.
\end{enumerate}
\begin{comment}
\item For any fixed $\theta$, define the real-valued 
function $f_\theta(x) := 1 âˆ’ \exp(-\theta|x|)$, and consider the function class
$$\F=\{f_\theta:[0,1]\rightarrow \R | \theta\in[0,1]	\}$$
Using the uniform norm as a metric, i.e. 

$\|f-g\|_\infty:=\sup_{x\in [0,1]}|f(x)-g(x)|$. Prove that 
$$\lfloor\frac{1-1/e}{2\delta}\rfloor+1\leq N_\infty(\delta;\F,\rho)\leq \frac{1}{2\delta}+2.$$
\end{comment}
\end{enumerate}

\end{document} 
